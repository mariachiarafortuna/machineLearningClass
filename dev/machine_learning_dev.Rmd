---
title: "Machine Learning Dev"
output:
  html_document:
    df_print: paged
---

# Libraries

```{r}
library(dplyr)
library(ggplot2)
library(rpart)
library(here)

```

# DATA IMPORT

```{r}
marvel <- file.path(here(), "data", "marvel-wikia-data.csv") %>%
  read.csv()

dc <-  file.path(here(), "data", "dc-wikia-data.csv") %>%
  read.csv()

max_year <- max(dc$YEAR, na.rm =T)

dc <-  dc %>%
  mutate(active_years = max_year - YEAR) %>%
  arrange(desc(active_years))

dc_class <- dc %>%
  filter((ALIGN == "Bad Characters" | ALIGN == "Good Characters") & 
           (SEX == "Female Characters" | SEX == "Male Characters")) %>%
  na.omit


```


# DATA EXPLORATION

## Dataset structure

```{r}
str(dc)
```


## Summary information

```{r}
summary(dc)
```


## Simple stats

### Range

```{r}
min(dc$YEAR)

min(dc$YEAR, na.rm = T)

max(dc$YEAR, na.rm = T)

range(dc$YEAR, na.rm = T)
```


### Mean and Sd

```{r}
mean(dc$APPEARANCES, na.rm = T)

sd(dc$APPEARANCES, na.rm = T)
```


## Frequency tables

### Univariate

```{r}
table(dc$EYE)
```

### Bivariate

```{r}
ID_SEX_freq  <- table(dc$ID, dc$SEX)

ID_SEX_freq
```


```{r}
margin.table(ID_SEX_freq, margin = 1)
```



```{r}
prop.table(ID_SEX_freq)
```

```{r}
prop.table(ID_SEX_freq, margin = 2)
```


## DATA MANIPULATION

### Create a new column: Mutate

```{r}
max_year <- max(dc$YEAR, na.rm =T)

dc <-  dc %>%
  mutate(active_years = max_year - YEAR) %>%
  arrange(desc(active_years))
  
```


### Subsetting data (rows and columns)

```{r}
the_bad <- dc %>%
  filter(ALIGN == "Bad Characters") %>%
  select(name, ID, SEX, ALIVE, YEAR, APPEARANCES, FIRST.APPEARANCE, active_years)

```


### More complex summary stats

```{r}
the_bad %>%
  group_by(SEX) %>%
  summarize(n = n(),
            avg_appearance = mean(APPEARANCES, na.rm = T),
            avg_active_year = mean(active_years, na.rm = T))
```


## DATA VISUALIZATION


### Histogram

```{r}
ggplot(data=dc, aes(x = YEAR)) +
  geom_bar()
```


#### Hist with grouping variable 

```{r}
ggplot(data=dc, aes(x = YEAR, fill = SEX)) +
  geom_bar()
```


#### Percent values

```{r}

YEAR_SEX_tab <- dc %>%
  group_by(YEAR, SEX) %>%
  summarize(n = n())

margin <- dc %>%
  group_by(YEAR) %>%
  summarize(tot = n())

perc_ys <- YEAR_SEX_tab %>%
  inner_join(margin) %>%
  mutate(perc = (n/tot)*100)


ggplot(data=perc_ys, aes(x = YEAR, y = perc, fill = SEX)) +
  geom_bar(stat = "identity")


```



###  Pie chart

```{r}

eye_tab <- dc %>%
  filter(EYE != "") %>%
  group_by(EYE) %>%
  summarize(count = n())

 ggplot(data=eye_tab, 
       aes(x=factor(1), y = count, fill = factor(EYE))) +
   geom_bar(width = 1, stat = "identity") +
   coord_polar(theta = "y")

```



### Scatterplot 


```{r}
ggplot(data = dc %>% filter(APPEARANCES<500), aes(x = active_years, y = APPEARANCES)) +
  geom_point()
  
```


```{r}
ggplot(data = dc %>% filter(APPEARANCES<500), aes(x = YEAR, y = log(APPEARANCES), color = ALIVE)) +
  geom_point()
```


```{r}
ggplot(data = dc %>% filter(APPEARANCES<500 & APPEARANCES>20), aes(x = YEAR, y = APPEARANCES, color = SEX)) +
  geom_point()
```


# DATA MODELING

## LINEAR REGRESSION

### Simple linear regression


### Easy ex

```{r}
ggplot(data = cars, aes(x = dist, y = speed)) +
  geom_point() +
  geom_smooth(method='lm',formula=y~x)

m1 <- lm(data = cars, speed ~ dist)

summary(m1)

residuals(m1)
predict(m1)

plot(m1)
```


### Comics example


```{r}
dc_small <- dc %>%
  filter(APPEARANCES >20) 

dc %>%
  ggplot(aes(x = active_years, y = APPEARANCES)) +
  geom_point()

dc_small %>%
  ggplot(aes(x = active_years, y = APPEARANCES, col = ID)) +
  geom_point()
```



```{r}

m1 <- lm(data=dc_small, APPEARANCES ~ active_years)

summary(m1)

plot(m1)

```

### Multiple linear regression

```{r}

m3 <- lm(data=dc, APPEARANCES ~ active_years + ALIGN)

summary(m3)

plot(m3)

```


```{r}
m4 <- lm(data=dc, APPEARANCES ~ active_years + ALIGN + active_years*ALIGN)

summary(m4)

plot(m4)
```



### Log-level regression

http://www.cazaar.com/ta/econ113/interpreting-beta


```{r}
dc %>%
  ggplot(aes(x = APPEARANCES)) +
  geom_density()
```

```{r}
dc %>%
  ggplot(aes(x = log(APPEARANCES))) +
  geom_density()
```



```{r}
dc %>%
  ggplot(aes(x = active_years, y = log(APPEARANCES), col = ID)) +
  geom_point()
```


```{r}

m2_l <- lm(data=dc, log(APPEARANCES) ~ active_years)

summary(m2_l)

plot(m2_l)

```

Se aggiungiamo un altro anno di attività, ci aspettiamo che il numero di apparizioni cresca del 3%




```{r}

m3 <- lm(data=dc, log(APPEARANCES) ~ active_years + ALIGN)

summary(m3)

plot(m3)

```

Se aggiungiamo un altro anno di attività, ci aspettiamo che il numero di apparizioni cresca del 3%.
Se il personaggio è cattivo, però, ci aspettiamo un decremento del numero di apparizioni del 17%, mentre se è buono un incremento del 47%.

https://www.youtube.com/watch?v=wXC2kViEGz8



```{r}
m4 <- lm(data=dc, log(APPEARANCES) ~ active_years + ALIGN + active_years*ALIGN)

summary(m4)

plot(m4)
```


# LOGISTIC REGRESSION

https://datascienceplus.com/perform-logistic-regression-in-r/

```{r}

dc_log <- dc_class

l1 <- glm(data = dc_log, ALIGN ~ SEX, family = "binomial")

summary(l1)

post_l1 <- predict(l1, type = "response")

ALIGN_pred <- ifelse(post_l1>0.5,  "Good Characters", "Bad  Characters") 

misClasificError <- mean(ALIGN_pred != dc_log$ALIGN)
print(paste('Accuracy',1-misClasificError))

table(dc_log$ALIGN)
table(ALIGN_pred)

table(dc_log$ALIGN, ALIGN_pred)


```


```{r}

ggp <- ggplot(data = dc_class, mapping = aes(x = active_years, y = ALIGN)) +
  geom_point(colour="blue") +
  #geom_line(mapping = aes(x = active_years, y = ALIGN), colour="red") +
  facet_wrap(facets = ~SEX)
print(ggp)

l2 <- glm(data = dc_class, ALIGN ~ SEX + active_years, family = "binomial")

summary(l2)

post_l2 <- predict(l2, type = "response")

ALIGN_pred_l2 <- ifelse(post_l2>0.5,  "Good Characters", "Bad  Characters") 

misClasificError <- mean(ALIGN_pred_l2 != dc_class$ALIGN)
print(paste('Accuracy',1-misClasificError))

table(dc_class$ALIGN, ALIGN_pred_l2)

anova(l2, test="Chisq")

```


```{r}
l3 <- glm(data = dc_class, ALIGN ~ SEX + active_years + APPEARANCES, family = "binomial")

summary(l3)

post_l3 <- predict(l3, type = "response")

ALIGN_pred_l3 <- ifelse(post_l3>0.5,  "Good Characters", "Bad  Characters") 

misClasificError <- mean(ALIGN_pred_l3 != dc_class$ALIGN)
print(paste('Accuracy',1-misClasificError))

table(dc_class$ALIGN, ALIGN_pred_l3)

anova(l3, test="Chisq")
```



# DECISION TREE

https://gormanalysis.com/decision-trees-in-r-using-rpart/

```{r}
library(rpart)

table(iris$Species)


iris_tree <- rpart(Species ~ ., method = "class", data = iris)

print(iris_tree)

summary(iris_tree)

plot(iris_tree, compress = T, margin = 0.2, branch = 0.3)
text(iris_tree, use.n = T, digits = 3, cex = 0.8)

printcp(iris_tree)

iris_pred <- predict(iris_tree, type = "class")

table(iris_pred, iris$Species)

misClasificError <- mean(iris_pred != iris$Species)
print(paste('Accuracy',1-misClasificError))

```




```{r}

align_tree <- rpart(ALIGN ~ SEX + active_years + APPEARANCES, method = "class", data = dc_class) 

summary(align_tree)

# require(rpart.plot)
# require(rattle)
# fancyRpartPlot(al)


plot(align_tree, uniform = T, compress = T, margin = 0.2, branch = 0.3)
text(align_tree, use.n = T, digits = 3, cex = 0.6)

align_pred_tree <- predict(align_tree, type = "class")

table(align_pred_tree, dc_class$ALIGN)

misClasificError <- mean(align_pred_tree != dc_class$ALIGN)
print(paste('Accuracy',1-misClasificError))


```


# Training and test dataset

```{r}
train <- sample(nrow(dc_class), 4800)
dc_train <- dc_class[train,]
dc_test <- dc_class[-train,]
```



# Random Forest

```{r}
# require(randomForest)
# set.seed(1000)
# 
# (rf_fit <- randomForest(x = dc_train[ , c("APPEARANCES","SEX", "active_years")], 
#                         y = dc_train[ , "ALIGN"],
#                         xtest = dc_test[ , c("APPEARANCES","SEX", "active_years")], 
#                         ytest = dc_test[ , "ALIGN"],
#                         cutoff = c(0.8, 0.2)))
# 
# 
# set.seed(71)
# iris.rf <- randomForest(Species ~ ., data=iris, importance=TRUE,
#                         proximity=TRUE)
# print(iris.rf)
# ## Look at variable importance:
# round(importance(iris.rf), 2)

```

